{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtIg0X9aKPDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXCjm7oMLYja",
        "colab_type": "code",
        "outputId": "4cf7f573-0683-4797-c861-6d0f1efab281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK3EhkBOL9p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install librosa\n",
        "import librosa\n",
        "s, sr=librosa.load('/content/drive/My Drive/data/train_clean_male.wav', sr=None)\n",
        "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr=librosa.load('/content/drive/My Drive/data/train_dirty_male.wav', sr=None)\n",
        "X=librosa.stft(sn, n_fft=1024, hop_length=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhX9qPSWMSsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now that the network has been trained, let us load the test data\n",
        "\n",
        "t, sr=librosa.load('/content/drive/My Drive/data/test_x_01.wav', sr=None)\n",
        "X_test1=librosa.stft(t, n_fft=1024, hop_length=512)\n",
        "\n",
        "t2, sr=librosa.load('/content/drive/My Drive/data/test_x_02.wav', sr=None)\n",
        "X_test2=librosa.stft(t2, n_fft=1024, hop_length=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZypYq-c2MaFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mag_X = np.abs(X)\n",
        "mag_S = np.abs(S)\n",
        "mag_X_test1 = np.abs(X_test1)\n",
        "mag_X_test2 = np.abs(X_test2)\n",
        "\n",
        "trans_mag_X = np.transpose(mag_X)\n",
        "trans_mag_S = np.transpose(mag_S)\n",
        "trans_mag_X_test1 = np.transpose(mag_X_test1)\n",
        "trans_mag_X_test2 = np.transpose(mag_X_test2)\n",
        "\n",
        "x = tf.placeholder('float',[None,513])\n",
        "y = tf.placeholder('float',[None,513])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNNOh85bNREC",
        "colab_type": "code",
        "outputId": "14fc3956-8aa9-4f6b-d9a9-e93e7e038585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "#Question 1\n",
        "\n",
        "input_layer = tf.reshape(x, shape=[-1, 513, 1])\n",
        "\n",
        "conv1d_layer1 = tf.layers.conv1d(inputs = input_layer, filters = 16, kernel_size = 16, padding = \"SAME\", activation = tf.nn.relu)\n",
        "maxpool1d_layer1 = tf.layers.max_pooling1d(inputs = conv1d_layer1, pool_size = 2, strides = 2)\n",
        "\n",
        "conv1d_layer2 = tf.layers.conv1d(inputs = maxpool1d_layer1, filters = 32, kernel_size = 8, padding=\"SAME\", activation = tf.nn.relu)\n",
        "maxpool1d_layer2 = tf.layers.max_pooling1d(inputs = conv1d_layer2, pool_size = 2, strides = 2)\n",
        "\n",
        "conv_flatten = tf.layers.flatten(maxpool1d_layer2)\n",
        "  \n",
        "output = tf.layers.dense(inputs=conv_flatten, units=513, activation=tf.nn.relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-ab348cc49d90>:4: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-ab348cc49d90>:5: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling1D instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-ab348cc49d90>:10: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-ab348cc49d90>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh7okxiqmmKY",
        "colab_type": "code",
        "outputId": "43875375-11d1-463d-ad16-0d53c263758b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "def train_neural_network(x):\n",
        "  \n",
        "  global final_layer_test1\n",
        "  global final_layer_test2\n",
        "  global final_layer_train\n",
        "  \n",
        "  prediction = output\n",
        "  cost = tf.reduce_mean(tf.square(prediction-y))\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "  hm_epochs = 100\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for epoch in range(hm_epochs):\n",
        "      \n",
        "      epoch_loss = 0\n",
        "      \n",
        "      for _ in range(int(trans_mag_X.shape[0]/100)):\n",
        "        start = _*100\n",
        "        end = (_*100) + (100-1)\n",
        "        epoch_x = trans_mag_X[start:end,:]\n",
        "        epoch_y = trans_mag_S[start:end,:]\n",
        "        _, c = sess.run([optimizer,cost],feed_dict = {x: epoch_x, y: epoch_y})\n",
        "        \n",
        "        epoch_loss += c\n",
        "\n",
        "      print('Epoch', epoch+1, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
        "    \n",
        "    final_layer_test1 = sess.run(prediction,feed_dict = {x:trans_mag_X_test1})\n",
        "    final_layer_test2 = sess.run(prediction,feed_dict = {x:trans_mag_X_test2})\n",
        "    final_layer_train = sess.run(prediction,feed_dict = {x:trans_mag_X})\n",
        "      \n",
        "train_neural_network(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed out of 100 loss: 1.696570586413145\n",
            "Epoch 2 completed out of 100 loss: 1.218347080051899\n",
            "Epoch 3 completed out of 100 loss: 0.7938978178426623\n",
            "Epoch 4 completed out of 100 loss: 0.5679759415797889\n",
            "Epoch 5 completed out of 100 loss: 0.45821112347766757\n",
            "Epoch 6 completed out of 100 loss: 0.3924139169976115\n",
            "Epoch 7 completed out of 100 loss: 0.3500605756416917\n",
            "Epoch 8 completed out of 100 loss: 0.32819020142778754\n",
            "Epoch 9 completed out of 100 loss: 0.2965543402824551\n",
            "Epoch 10 completed out of 100 loss: 0.27049294323660433\n",
            "Epoch 11 completed out of 100 loss: 0.25296554900705814\n",
            "Epoch 12 completed out of 100 loss: 0.22713872767053545\n",
            "Epoch 13 completed out of 100 loss: 0.21671845763921738\n",
            "Epoch 14 completed out of 100 loss: 0.21117949346080422\n",
            "Epoch 15 completed out of 100 loss: 0.2010033444967121\n",
            "Epoch 16 completed out of 100 loss: 0.20338364993222058\n",
            "Epoch 17 completed out of 100 loss: 0.19186382414773107\n",
            "Epoch 18 completed out of 100 loss: 0.18095195316709578\n",
            "Epoch 19 completed out of 100 loss: 0.1810856785159558\n",
            "Epoch 20 completed out of 100 loss: 0.17822677525691688\n",
            "Epoch 21 completed out of 100 loss: 0.1719762224238366\n",
            "Epoch 22 completed out of 100 loss: 0.17431042552925646\n",
            "Epoch 23 completed out of 100 loss: 0.1614635733421892\n",
            "Epoch 24 completed out of 100 loss: 0.15457280655391514\n",
            "Epoch 25 completed out of 100 loss: 0.15951979160308838\n",
            "Epoch 26 completed out of 100 loss: 0.15254113799892366\n",
            "Epoch 27 completed out of 100 loss: 0.1506274917628616\n",
            "Epoch 28 completed out of 100 loss: 0.15664867660962045\n",
            "Epoch 29 completed out of 100 loss: 0.14362915325909853\n",
            "Epoch 30 completed out of 100 loss: 0.1415220000781119\n",
            "Epoch 31 completed out of 100 loss: 0.14724858989939094\n",
            "Epoch 32 completed out of 100 loss: 0.13673310377635062\n",
            "Epoch 33 completed out of 100 loss: 0.13630713010206819\n",
            "Epoch 34 completed out of 100 loss: 0.1403770544566214\n",
            "Epoch 35 completed out of 100 loss: 0.13297036685980856\n",
            "Epoch 36 completed out of 100 loss: 0.1297254932578653\n",
            "Epoch 37 completed out of 100 loss: 0.1355482107028365\n",
            "Epoch 38 completed out of 100 loss: 0.1314358136150986\n",
            "Epoch 39 completed out of 100 loss: 0.13242248515598476\n",
            "Epoch 40 completed out of 100 loss: 0.1403416832908988\n",
            "Epoch 41 completed out of 100 loss: 0.12716833630111068\n",
            "Epoch 42 completed out of 100 loss: 0.12163611908908933\n",
            "Epoch 43 completed out of 100 loss: 0.12228609493467957\n",
            "Epoch 44 completed out of 100 loss: 0.11901956552173942\n",
            "Epoch 45 completed out of 100 loss: 0.12130935851018876\n",
            "Epoch 46 completed out of 100 loss: 0.12874569941777736\n",
            "Epoch 47 completed out of 100 loss: 0.12256513733882457\n",
            "Epoch 48 completed out of 100 loss: 0.12288923864252865\n",
            "Epoch 49 completed out of 100 loss: 0.12744468974415213\n",
            "Epoch 50 completed out of 100 loss: 0.12025438714772463\n",
            "Epoch 51 completed out of 100 loss: 0.11861788621172309\n",
            "Epoch 52 completed out of 100 loss: 0.1225993491243571\n",
            "Epoch 53 completed out of 100 loss: 0.11576021404471248\n",
            "Epoch 54 completed out of 100 loss: 0.1123598056146875\n",
            "Epoch 55 completed out of 100 loss: 0.11333605565596372\n",
            "Epoch 56 completed out of 100 loss: 0.11033499671611935\n",
            "Epoch 57 completed out of 100 loss: 0.10733911907300353\n",
            "Epoch 58 completed out of 100 loss: 0.10937020904384553\n",
            "Epoch 59 completed out of 100 loss: 0.10841996071394533\n",
            "Epoch 60 completed out of 100 loss: 0.10824966954533011\n",
            "Epoch 61 completed out of 100 loss: 0.11007834214251488\n",
            "Epoch 62 completed out of 100 loss: 0.10814664280042052\n",
            "Epoch 63 completed out of 100 loss: 0.1088010836392641\n",
            "Epoch 64 completed out of 100 loss: 0.11125854309648275\n",
            "Epoch 65 completed out of 100 loss: 0.10807960876263678\n",
            "Epoch 66 completed out of 100 loss: 0.10668222245294601\n",
            "Epoch 67 completed out of 100 loss: 0.10652250191196799\n",
            "Epoch 68 completed out of 100 loss: 0.1064207759918645\n",
            "Epoch 69 completed out of 100 loss: 0.10580097895581275\n",
            "Epoch 70 completed out of 100 loss: 0.10589716234244406\n",
            "Epoch 71 completed out of 100 loss: 0.10530614585150033\n",
            "Epoch 72 completed out of 100 loss: 0.10148234479129314\n",
            "Epoch 73 completed out of 100 loss: 0.1022699853638187\n",
            "Epoch 74 completed out of 100 loss: 0.10406053310725838\n",
            "Epoch 75 completed out of 100 loss: 0.09999302076175809\n",
            "Epoch 76 completed out of 100 loss: 0.09985959669575095\n",
            "Epoch 77 completed out of 100 loss: 0.10248449689242989\n",
            "Epoch 78 completed out of 100 loss: 0.09861581842415035\n",
            "Epoch 79 completed out of 100 loss: 0.09806886874139309\n",
            "Epoch 80 completed out of 100 loss: 0.10107081185560673\n",
            "Epoch 81 completed out of 100 loss: 0.09677776379976422\n",
            "Epoch 82 completed out of 100 loss: 0.09748778666835278\n",
            "Epoch 83 completed out of 100 loss: 0.10289814660791308\n",
            "Epoch 84 completed out of 100 loss: 0.09908665588591248\n",
            "Epoch 85 completed out of 100 loss: 0.09860982466489077\n",
            "Epoch 86 completed out of 100 loss: 0.10102384572383016\n",
            "Epoch 87 completed out of 100 loss: 0.09517047076951712\n",
            "Epoch 88 completed out of 100 loss: 0.09405259066261351\n",
            "Epoch 89 completed out of 100 loss: 0.09533679345622659\n",
            "Epoch 90 completed out of 100 loss: 0.09029222093522549\n",
            "Epoch 91 completed out of 100 loss: 0.09180848184041679\n",
            "Epoch 92 completed out of 100 loss: 0.09021995088551193\n",
            "Epoch 93 completed out of 100 loss: 0.08782207465264946\n",
            "Epoch 94 completed out of 100 loss: 0.09010498342104256\n",
            "Epoch 95 completed out of 100 loss: 0.08902182697784156\n",
            "Epoch 96 completed out of 100 loss: 0.08739892370067537\n",
            "Epoch 97 completed out of 100 loss: 0.08869456534739584\n",
            "Epoch 98 completed out of 100 loss: 0.08900043182075024\n",
            "Epoch 99 completed out of 100 loss: 0.08775131253059953\n",
            "Epoch 100 completed out of 100 loss: 0.0890519677195698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32Ll4wU3jXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "S_test1 = X_test1/mag_X_test1\n",
        "S_test1 = np.multiply(S_test1,np.transpose(final_layer_test1))\n",
        "\n",
        "S_test2 = X_test2/mag_X_test2\n",
        "S_test2 = np.multiply(S_test2,np.transpose(final_layer_test2))\n",
        "\n",
        "S_train = X/mag_X\n",
        "S_train = np.multiply(S_train,np.transpose(final_layer_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9O3sNlKgANm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_test1 = librosa.istft(S_test1, hop_length=512)\n",
        "librosa.output.write_wav('1d_test_s_01_reconstruct.wav', s_test1, sr)\n",
        "\n",
        "s_test2 = librosa.istft(S_test2, hop_length=512)\n",
        "librosa.output.write_wav('1d_test_s_02_reconstruct.wav', s_test2, sr)\n",
        "\n",
        "s_train = librosa.istft(S_train, hop_length=512)\n",
        "librosa.output.write_wav('1d_train_reconstruct.wav', s_train, sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lOKPMi0gUaH",
        "colab_type": "code",
        "outputId": "c2c7994a-1fc9-4174-a40b-3d6a7e1f895f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "size = np.shape(s_train)[0]\n",
        "s = s[: size]\n",
        "num = np.dot(np.transpose(s),s)\n",
        "den = np.dot(np.transpose(s - s_train),(s - s_train))\n",
        "SNR = 10 * np.log10(num/den)\n",
        "print('Value of SNR : ' + str(SNR))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of SNR : 14.344884157180786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5FQVieS_7LX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question 2\n",
        "\n",
        "x = tf.placeholder('float',[None,20,513])\n",
        "y = tf.placeholder('float',[None,513])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0s80v-Vj8cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scan(z):\n",
        "  new_list = []\n",
        "  for i in range(0,len(z)-19):\n",
        "    new_list.append(z[i:i+20,:])\n",
        "  return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Dgn4FqKbS0",
        "colab_type": "code",
        "outputId": "a8525153-df2b-4d7d-e9fd-12e0beb95f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "input_layer = tf.reshape(x, shape=[-1, 20, 513, 1])\n",
        "\n",
        "conv2d_layer1 = tf.layers.conv2d(inputs = input_layer, filters = 16, kernel_size = [4,4], strides = [1,1], padding = \"SAME\", activation = tf.nn.relu)\n",
        "maxpool2d_layer1 = tf.layers.max_pooling2d(inputs = conv2d_layer1, pool_size = [2,2], strides = [2,2])\n",
        "\n",
        "conv2d_layer2 = tf.layers.conv2d(inputs = maxpool2d_layer1, filters = 32, kernel_size = [2,2], strides = [1,1], padding=\"SAME\", activation = tf.nn.relu)\n",
        "maxpool2d_layer2 = tf.layers.max_pooling2d(inputs = conv2d_layer2, pool_size = [2,2], strides = [2,2])\n",
        "\n",
        "conv_flatten = tf.layers.flatten(maxpool2d_layer2)\n",
        "  \n",
        "output1 = tf.layers.dense(inputs=conv_flatten, units=1024, activation=tf.nn.relu)\n",
        "\n",
        "drop_out = tf.nn.dropout(output1,rate=0.2)\n",
        "\n",
        "output = tf.layers.dense(inputs=drop_out, units=513, activation=tf.nn.relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-1f1a04a0beb6>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From <ipython-input-13-1f1a04a0beb6>:4: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkPjNlyp5s8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_trans_mag_X = scan(trans_mag_X)\n",
        "new_trans_mag_X_test1 = scan(trans_mag_X_test1)\n",
        "new_trans_mag_X_test2 = scan(trans_mag_X_test2)\n",
        "\n",
        "new_trans_mag_S = trans_mag_S[19:,:]\n",
        "new_trans_mag_X = np.reshape(new_trans_mag_X , (len(new_trans_mag_X) , 20 , 513))\n",
        "new_trans_mag_X_test1 = np.reshape(new_trans_mag_X_test1 , (len(new_trans_mag_X_test1) , 20 , 513))\n",
        "new_trans_mag_X_test2 = np.reshape(new_trans_mag_X_test2 , (len(new_trans_mag_X_test2) , 20 , 513))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOVdouZHY992",
        "colab_type": "code",
        "outputId": "69f21997-654e-48ae-8548-efeead63bf3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "cost = tf.reduce_mean(tf.square(output-y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "hm_epochs = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for epoch in range(hm_epochs):\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _ in range(int(len(new_trans_mag_X)/128)):\n",
        "      start = _*128\n",
        "      end = (_*128) + (128-1)\n",
        "      epoch_x = new_trans_mag_X[start:end]\n",
        "      epoch_y = new_trans_mag_S[start:end]\n",
        "      \n",
        "      epoch_x = epoch_x.reshape(np.shape(epoch_x)[0] , np.shape(epoch_x)[1] , np.shape(epoch_x)[2])\n",
        "      \n",
        "      _, c = sess.run([optimizer,cost],feed_dict = {x: epoch_x, y: epoch_y})\n",
        "\n",
        "      epoch_loss += c\n",
        "\n",
        "    print('Epoch', epoch+1, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
        "  \n",
        "  final_layer_test1 = sess.run(output,feed_dict = {x:new_trans_mag_X_test1})\n",
        "  final_layer_test2 = sess.run(output,feed_dict = {x:new_trans_mag_X_test2})\n",
        "  final_layer_train = sess.run(output,feed_dict = {x:new_trans_mag_X})\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed out of 100 loss: 1.922581534832716\n",
            "Epoch 2 completed out of 100 loss: 1.437642678618431\n",
            "Epoch 3 completed out of 100 loss: 1.2326178010553122\n",
            "Epoch 4 completed out of 100 loss: 1.060838183388114\n",
            "Epoch 5 completed out of 100 loss: 0.9023817908018827\n",
            "Epoch 6 completed out of 100 loss: 0.7676181001588702\n",
            "Epoch 7 completed out of 100 loss: 0.6792701613157988\n",
            "Epoch 8 completed out of 100 loss: 0.6177981644868851\n",
            "Epoch 9 completed out of 100 loss: 0.5452281879261136\n",
            "Epoch 10 completed out of 100 loss: 0.4892150992527604\n",
            "Epoch 11 completed out of 100 loss: 0.45857666805386543\n",
            "Epoch 12 completed out of 100 loss: 0.42620926443487406\n",
            "Epoch 13 completed out of 100 loss: 0.40404571406543255\n",
            "Epoch 14 completed out of 100 loss: 0.40127144381403923\n",
            "Epoch 15 completed out of 100 loss: 0.3851292347535491\n",
            "Epoch 16 completed out of 100 loss: 0.3848615000024438\n",
            "Epoch 17 completed out of 100 loss: 0.35299691604450345\n",
            "Epoch 18 completed out of 100 loss: 0.35740442015230656\n",
            "Epoch 19 completed out of 100 loss: 0.382345424965024\n",
            "Epoch 20 completed out of 100 loss: 0.3635149421170354\n",
            "Epoch 21 completed out of 100 loss: 0.35076299076899886\n",
            "Epoch 22 completed out of 100 loss: 0.3445122675038874\n",
            "Epoch 23 completed out of 100 loss: 0.3192675639875233\n",
            "Epoch 24 completed out of 100 loss: 0.2930631232447922\n",
            "Epoch 25 completed out of 100 loss: 0.28715857630595565\n",
            "Epoch 26 completed out of 100 loss: 0.2760453335940838\n",
            "Epoch 27 completed out of 100 loss: 0.2622342496179044\n",
            "Epoch 28 completed out of 100 loss: 0.2622191230766475\n",
            "Epoch 29 completed out of 100 loss: 0.24916989728808403\n",
            "Epoch 30 completed out of 100 loss: 0.23896454321220517\n",
            "Epoch 31 completed out of 100 loss: 0.23372176056727767\n",
            "Epoch 32 completed out of 100 loss: 0.2427346301265061\n",
            "Epoch 33 completed out of 100 loss: 0.23696701042354107\n",
            "Epoch 34 completed out of 100 loss: 0.22770099947229028\n",
            "Epoch 35 completed out of 100 loss: 0.22740205843001604\n",
            "Epoch 36 completed out of 100 loss: 0.22119178948923945\n",
            "Epoch 37 completed out of 100 loss: 0.21930278185755014\n",
            "Epoch 38 completed out of 100 loss: 0.2342399819754064\n",
            "Epoch 39 completed out of 100 loss: 0.24626545701175928\n",
            "Epoch 40 completed out of 100 loss: 0.22207085462287068\n",
            "Epoch 41 completed out of 100 loss: 0.21717335609719157\n",
            "Epoch 42 completed out of 100 loss: 0.21090473840013146\n",
            "Epoch 43 completed out of 100 loss: 0.20387811632826924\n",
            "Epoch 44 completed out of 100 loss: 0.2084112223237753\n",
            "Epoch 45 completed out of 100 loss: 0.20794046623632312\n",
            "Epoch 46 completed out of 100 loss: 0.19560985639691353\n",
            "Epoch 47 completed out of 100 loss: 0.19964840495958924\n",
            "Epoch 48 completed out of 100 loss: 0.20467234635725617\n",
            "Epoch 49 completed out of 100 loss: 0.19203209318220615\n",
            "Epoch 50 completed out of 100 loss: 0.20477124233730137\n",
            "Epoch 51 completed out of 100 loss: 0.21368740359321237\n",
            "Epoch 52 completed out of 100 loss: 0.187210273463279\n",
            "Epoch 53 completed out of 100 loss: 0.18705308274365962\n",
            "Epoch 54 completed out of 100 loss: 0.17406273493543267\n",
            "Epoch 55 completed out of 100 loss: 0.17063379590399563\n",
            "Epoch 56 completed out of 100 loss: 0.18784966226667166\n",
            "Epoch 57 completed out of 100 loss: 0.17048243712633848\n",
            "Epoch 58 completed out of 100 loss: 0.1660911929793656\n",
            "Epoch 59 completed out of 100 loss: 0.1647096809465438\n",
            "Epoch 60 completed out of 100 loss: 0.16566279367543757\n",
            "Epoch 61 completed out of 100 loss: 0.1635804451070726\n",
            "Epoch 62 completed out of 100 loss: 0.16360637452453375\n",
            "Epoch 63 completed out of 100 loss: 0.16102778376080096\n",
            "Epoch 64 completed out of 100 loss: 0.16130083054304123\n",
            "Epoch 65 completed out of 100 loss: 0.1586761800572276\n",
            "Epoch 66 completed out of 100 loss: 0.15930183068849146\n",
            "Epoch 67 completed out of 100 loss: 0.16353030409663916\n",
            "Epoch 68 completed out of 100 loss: 0.14991365070454776\n",
            "Epoch 69 completed out of 100 loss: 0.15111737721599638\n",
            "Epoch 70 completed out of 100 loss: 0.14962491602636874\n",
            "Epoch 71 completed out of 100 loss: 0.15892947115935385\n",
            "Epoch 72 completed out of 100 loss: 0.16890438180416822\n",
            "Epoch 73 completed out of 100 loss: 0.1605597424786538\n",
            "Epoch 74 completed out of 100 loss: 0.1507800193503499\n",
            "Epoch 75 completed out of 100 loss: 0.15273906057700515\n",
            "Epoch 76 completed out of 100 loss: 0.1502455254085362\n",
            "Epoch 77 completed out of 100 loss: 0.14559013885445893\n",
            "Epoch 78 completed out of 100 loss: 0.147526795277372\n",
            "Epoch 79 completed out of 100 loss: 0.15026634698733687\n",
            "Epoch 80 completed out of 100 loss: 0.14625008893199265\n",
            "Epoch 81 completed out of 100 loss: 0.14631571085192263\n",
            "Epoch 82 completed out of 100 loss: 0.1513692361768335\n",
            "Epoch 83 completed out of 100 loss: 0.15301568643189967\n",
            "Epoch 84 completed out of 100 loss: 0.16321421787142754\n",
            "Epoch 85 completed out of 100 loss: 0.14873685222119093\n",
            "Epoch 86 completed out of 100 loss: 0.15441745519638062\n",
            "Epoch 87 completed out of 100 loss: 0.15005878638476133\n",
            "Epoch 88 completed out of 100 loss: 0.15211677784100175\n",
            "Epoch 89 completed out of 100 loss: 0.1563716591335833\n",
            "Epoch 90 completed out of 100 loss: 0.1501020099967718\n",
            "Epoch 91 completed out of 100 loss: 0.14400658034719527\n",
            "Epoch 92 completed out of 100 loss: 0.14449212537147105\n",
            "Epoch 93 completed out of 100 loss: 0.14755858317948878\n",
            "Epoch 94 completed out of 100 loss: 0.13982806261628866\n",
            "Epoch 95 completed out of 100 loss: 0.1490403045900166\n",
            "Epoch 96 completed out of 100 loss: 0.1414198714774102\n",
            "Epoch 97 completed out of 100 loss: 0.14681718195788562\n",
            "Epoch 98 completed out of 100 loss: 0.14507118402980268\n",
            "Epoch 99 completed out of 100 loss: 0.14983731205575168\n",
            "Epoch 100 completed out of 100 loss: 0.1550597387831658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMqOJgR9d5RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "silent_frames = np.empty([19,513])\n",
        "silent_frames.fill(1e-10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT2fGMB0YVzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "S_test1 = X_test1/mag_X_test1\n",
        "S_test1 = np.multiply(S_test1,np.vstack((silent_frames,final_layer_test1)).T)\n",
        "\n",
        "S_test2 = X_test2/mag_X_test2\n",
        "S_test2 = np.multiply(S_test2,np.vstack((silent_frames,final_layer_test2)).T)\n",
        "\n",
        "S_train = X/mag_X\n",
        "S_train = np.multiply(S_train,np.vstack((silent_frames,final_layer_train)).T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZFqZDn7nMWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_test1 = librosa.istft(S_test1, hop_length=512)\n",
        "librosa.output.write_wav('2d_test_s_01_reconstruct.wav', s_test1, sr)\n",
        "\n",
        "s_test2 = librosa.istft(S_test2, hop_length=512)\n",
        "librosa.output.write_wav('2d_test_s_02_reconstruct.wav', s_test2, sr)\n",
        "\n",
        "s_train = librosa.istft(S_train, hop_length=512)\n",
        "librosa.output.write_wav('2d_train_reconstruct.wav', s_train, sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gJGkxWZpfNt",
        "colab_type": "code",
        "outputId": "4dfef737-523e-4b1e-db0c-1e10f8b29cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "size = np.shape(s_train)[0]\n",
        "s_train = s_train[: s.shape[0]]\n",
        "num = np.dot(np.transpose(s),s)\n",
        "den = np.dot(np.transpose(s - s_train),(s - s_train))\n",
        "SNR = 10 * np.log10(num/den)\n",
        "print('Value of SNR : ' + str(SNR))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of SNR : 11.303973197937012\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}